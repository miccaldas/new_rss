[
{"title": "Solving (Some) Formal Math Olympiad Problems", "links": "/", "content": "We built a neural theorem prover for ", "images": []},
{"title": "missing", "links": "/", "content": " that learned to solve a variety of challenging high-school olympiad problems, including problems from the ", "images": []},
{"title": "missing", "links": "/api/", "content": " and ", "images": []},
{"title": "missing", "links": "/research/", "content": " competitions, as well as two problems adapted from the ", "images": []},
{"title": "missing", "links": "/blog/", "content": ".", "images": []},
{"title": "missing", "links": "/about/", "content": " The prover uses a language model to find proofs of formal statements. Each time we find a new proof, we use it as new training data, which improves the neural network and enables it to iteratively find solutions to harder and harder statements.", "images": []},
{"title": "missing", "links": "https://leanprover.github.io/", "content": "We achieved a new state-of-the-art (41.2% vs 29.3%) on the ", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/amc-1012", "content": " benchmark, a challenging collection of high-school olympiad problems. Our approach, which we call ", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/invitational-competitions", "content": ", consists of manually collecting a set of statements of varying difficulty levels (without proof) where the hardest statements are similar to the benchmark we target. Initially our neural prover is weak and can only prove a few of them. We iteratively search for new proofs and re-train our neural network on the newly discovered proofs, and after 8 iterations, our prover ends up being vastly superior when tested on miniF2F.", "images": []},
{"title": "missing", "links": "https://www.imo-official.org/", "content": "Formal mathematics is an exciting domain to study because of (i) its richness, letting you prove arbitrary theorems which require reasoning, creativity and insight and (ii) its similarity to games\u2014where AI has been spectacularly successful\u2014in that it has an automated way of determining whether a proof is successful (i.e., verified by the formal system). As demonstrated in the trivial example below, proving a formal statement requires generating a sequence of proof steps, each proof step consisting in a call to a tactic.", "images": []},
{"title": "missing", "links": "#fn1", "content": " These tactics take mathematical terms as arguments and each tactic call will transform the current statement to prove, into statements that are easier to prove, until nothing is left to prove.", "images": []},
{"title": "missing", "links": "https://cdn.openai.com/papers/Formal_Mathematics_Statement_Curriculum_Learning__ICML_2022.pdf", "content": "Since $x < 2$, $|x - 2| = -(x - 2)$. Using $p = |x - 2|$ we have $x = 2-p$ and finally $x - p = 2 - 2p$.", "images": []},
{"title": "missing", "links": "https://arxiv.org/abs/2109.00110", "content": "We observe that the capability to generate original mathematical terms required as arguments of tactics, which cannot be done without a neural language model, emerges from our training procedure. The proof below is an example of it: the proof step ", "images": []},
{"title": "missing", "links": "#fn2", "content": " (entirely generated by our models) proposes to use ", "images": []},
{"title": "missing", "links": "https://leanprover-community.github.io/mathlib_docs/tactic/ring_exp.html", "content": " as a solution, the rest of the formal proof relying on the ", "images": []},
{"title": "missing", "links": "https://leanprover-community.github.io/mathlib_docs/tactics.html#norm_num", "content": " tactic to verify that it is indeed valid.", "images": []},
{"title": "missing", "links": "#fn3", "content": "Expanding the expression we get:", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/amc-1012", "content": "$$((n + 2)! \u2212(n + 1)!) / n! = ((n + 2)(n+1)n! \u2212(n + 1)n!) / n!$$", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/invitational-competitions", "content": "Dividing by $n!$ we obtain:", "images": []},
{"title": "missing", "links": "https://www.imo-official.org/", "content": "$$(n+2)(n+1) - (n+1)$$", "images": []},
{"title": "missing", "links": "#fn4", "content": "Factoring $(n+1)$ we get: $(n+1)(n+2-1) = (n+1)^2$ which concludes the proof.", "images": []},
{"title": "missing", "links": "https://imo-grand-challenge.github.io/", "content": "We also observe that our models and search procedure are capable of producing proofs that chain multiple non-trivial reasoning steps. In the proof below, the model starts by using contraposition leading to the existential statement (", "images": []},
{"title": "missing", "links": "#fnref1", "content": "). It then generates a witness for it with ", "images": []},
{"title": "missing", "links": "#fnref2", "content": " and finishes the proof by leveraging the ", "images": []},
{"title": "missing", "links": "#fnref3", "content": " tactic.", "images": []},
{"title": "missing", "links": "#fnref4", "content": "\nLet $f(x) = Ax + B$ and $g(x) = Bx + A$, where $A \\ne B$. If $f(g(x)) - g(f(x)) = B - A$, prove that $A + B = 0$.", "images": []},
{"title": "missing", "links": "/blog/authors/stanislas/", "content": "First we find that:", "images": []},
{"title": "missing", "links": "/blog/authors/jesse/", "content": "$$f(g(x)) = A(Bx + A) + B = ABx + A^2 + B$$$$g(f(x)) = B(Ax + B) + A = ABx + B^2 + A$$", "images": []},
{"title": "missing", "links": "/blog/authors/ilya/", "content": "Now we plug this back in $f(g(x)) - g(f(x)) = B - A$ and get:", "images": []},
{"title": "missing", "links": "/blog/tags/research/", "content": "$$(ABx + A^2 + B) - (ABx + B^2 + A) = B - A$$", "images": []},
{"title": "missing", "links": "/", "content": "That is:", "images": []},
{"title": "missing", "links": "/blog/openai-codex/", "content": "$$A^2 - B^2 + B - A = B - A$$", "images": []},
{"title": "missing", "links": "/fund/", "content": "Hence:", "images": []},
{"title": "missing", "links": "/blog/multimodal-neurons/", "content": "$$A^2 - B^2 = (A-B)(A+B) = 0$$", "images": []},
{"title": "missing", "links": "/blog/dall-e/", "content": "Since we are given that $A \\ne B$, necessarily, $A + B = 0$.", "images": []},
{"title": "missing", "links": "/blog/clip/", "content": "Our models, trained with ", "images": []},
{"title": "missing", "links": "/api/", "content": ", were able to close a variety of problems from training textbooks as well as ", "images": []},
{"title": "missing", "links": "/api/pricing/", "content": " and ", "images": []},
{"title": "missing", "links": "/api/examples/", "content": " competitions, and 2 problems adapted from the ", "images": []},
{"title": "missing", "links": "/api/docs/", "content": ". We present below three examples of such generated proofs.", "images": []},
{"title": "missing", "links": "/api/policies/", "content": "Rearrange to get $a(a-b)(a-c) + b(b-a)(b-c) + c(c-a)(c-b) >= 0$ which is true by Schur's inequality.", "images": []},
{"title": "missing", "links": "https://status.openai.com/", "content": "For $n \\geq 1$ we have $a(2n-1) = a(2n)-1$. Substituting this into the equation given, we get:", "images": []},
{"title": "missing", "links": "/api/login/", "content": "$$(a(2)-1) + a(2) + (a(4)-1) + a(4) + \u2026 + (a(98)-1) + (a(98)) = 137$$", "images": []},
{"title": "missing", "links": "/blog/", "content": "But the left-hand side is simply $2(a2 + a4 + a6 + \u2026 + a98) - 49$, so:", "images": []},
{"title": "missing", "links": "/blog/tags/research/", "content": "$$(a2 + a4 + a6 + \u2026 + a98) = (137 + 49) / 2 = 93$$", "images": []},
{"title": "missing", "links": "/blog/tags/announcements/", "content": "\nFor $a, b, c$ reals, prove that $(a^2 + ab + b^2)(b^2 + bc + c^2)(c^2 + ca + a^2) \\geq (ab + bc + ca)^3$.", "images": []},
{"title": "missing", "links": "/blog/tags/events/", "content": "After cancelling terms appearing on both sides, we are left to prove that:", "images": []},
{"title": "missing", "links": "/blog/tags/milestones/", "content": "$$3a^2b^2c^2 + \\sum_{sym} a^3b^2c \\leq \\sum_{cyc} a^4bc + \\sum_{cyc} (a^4b^2 + b^4c^2)$$", "images": []},
{"title": "missing", "links": "/about/", "content": "After multiplying both sides by $2$, we can rearrange the above inequality to:", "images": []},
{"title": "missing", "links": "/research/", "content": "$$0 \\leq \\sum_{cyc} (a^2b + a^2c - b^2c)^2$$", "images": []},
{"title": "missing", "links": "/publications/", "content": "which clearly holds, giving the claim.", "images": []},
{"title": "missing", "links": "/charter/", "content": "Formal mathematics involves two main challenges that make a naive application of reinforcement learning unlikely to succeed.", "images": []},
{"title": "missing", "links": "/timeline/", "content": "In our work, we address the infinite action space problem by sampling actions from a language model as we search for a proof. Language models have the capability to generate the tactic calls as well as the original mathematical terms often required as arguments. Our basis for addressing the lack of self-play is the observation that the key role of self-play in 2-player games is to provide an unsupervised curriculum. Our methodology proposes to replace this unsupervised curriculum with an auxiliary set of problem statements (without requiring proofs) of varying difficulty. We empirically show that, when the difficulty of these auxiliary problems is varied enough, our training procedure is able to solve a curriculum of increasingly difficult problems, eventually generalizing to the set of problems we care about.", "images": []},
{"title": "missing", "links": "/newsroom/", "content": "While these results are extremely exciting, as they demonstrate that deep learning models are capable of non-trivial mathematical reasoning when interacting with a formal system, we are still very far from best-student performance on these competitions, only occasionally, rather than consistently, closing challenging olympiad problems. We hope nonetheless that our work will motivate research in this domain, in particular towards the ", "images": []},
{"title": "missing", "links": "/careers/", "content": " and that the ", "images": []},
{"title": "missing", "links": "/", "content": " methodology we propose will help accelerate progress in automated reasoning in general.", "images": []},
{"title": "missing", "links": "/privacy/", "content": "Thanks to our paper co-authors: Igor Babuschkin, Kunhao Zheng and Mantas Baksys.", "images": []},
{"title": "missing", "links": "/terms/", "content": "Thanks to the students of the Xena Project Discord who helped us formalize proofs and statements (in particular: Antoine Labelle, Hanting Zhang, Shing Tak Lam, Paul Lezeau, Sara Diaz, Nikita Golikov, Yael Dillies, Artem Vasilyev, Ollie Perree, and Yourong Zang).", "images": []},
{"title": "missing", "links": "https://twitter.com/openai", "content": "Thanks in particular to Kevin Buzzard and Daniel Selsam for their support and thoughtful feedback since the very beginning of this project.", "images": []},
{"title": "missing", "links": "https://youtube.com/openai", "content": "These problems are not standard math exercises, they are used to let the best high-school students from the US (AMC12, AIME) or the world (IMO) compete against each other. ", "images": []},
{"title": "missing", "links": "https://github.com/openai/", "content": "The artifacts accepted by the formal system are low-level (like assembly code) and hard for humans to produce. Tactics are search procedures that generate such artifacts from higher level directives to assist formalization. ", "images": []},
{"title": "missing", "links": "https://soundcloud.com/openai_audio", "content": "Addendum: It was reported to us that this formal statement has an error (it should be ", "images": []},
{"title": "missing", "links": "https://linkedin.com/company/openai", "content": " instead of ", "images": []},
{"title": "missing", "links": "https://facebook.com/openai.research/", "content": " in ", "images": []},
{"title": "missing", "links": "https://twitter.com/openai", "content": "). While this error unfortunately makes the statement significantly easier than its informal version, it's an interesting example of the challenges associated with formalizing problem statements: although Lean can verify with 100% confidence that a formal proof is a correct proof of a formal statement, there is no way to automatically verify that a formal statement is \"faithful\" to an informal one. The proof of the simplified statement remains interesting so we decided to keep it in the blog post and be explicit about it with this footnote. ", "images": []},
{"title": "missing", "links": "https://youtube.com/openai", "content": "This proof is not reported in the paper as it was found by a more recent model we are still experimenting with. We decided to share it nonetheles because it's one of our favourite. ", "images": []},
{"title": "missing", "links": "https://github.com/openai/", "content": "missing", "images": []},
{"title": "missing", "links": "https://soundcloud.com/openai_audio", "content": "missing", "images": []},
{"title": "missing", "links": "https://linkedin.com/company/openai", "content": "missing", "images": []},
{"title": "missing", "links": "https://facebook.com/openai.research/", "content": "missing", "images": []}
][
{"title": "Solving (Some) Formal Math Olympiad Problems", "links": "/", "content": "We built a neural theorem prover for ", "images": []},
{"title": "missing", "links": "/", "content": " that learned to solve a variety of challenging high-school olympiad problems, including problems from the ", "images": []},
{"title": "missing", "links": "/api/", "content": " and ", "images": []},
{"title": "missing", "links": "/research/", "content": " competitions, as well as two problems adapted from the ", "images": []},
{"title": "missing", "links": "/blog/", "content": ".", "images": []},
{"title": "missing", "links": "/about/", "content": " The prover uses a language model to find proofs of formal statements. Each time we find a new proof, we use it as new training data, which improves the neural network and enables it to iteratively find solutions to harder and harder statements.", "images": []},
{"title": "missing", "links": "https://leanprover.github.io/", "content": "We achieved a new state-of-the-art (41.2% vs 29.3%) on the ", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/amc-1012", "content": " benchmark, a challenging collection of high-school olympiad problems. Our approach, which we call ", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/invitational-competitions", "content": ", consists of manually collecting a set of statements of varying difficulty levels (without proof) where the hardest statements are similar to the benchmark we target. Initially our neural prover is weak and can only prove a few of them. We iteratively search for new proofs and re-train our neural network on the newly discovered proofs, and after 8 iterations, our prover ends up being vastly superior when tested on miniF2F.", "images": []},
{"title": "missing", "links": "https://www.imo-official.org/", "content": "Formal mathematics is an exciting domain to study because of (i) its richness, letting you prove arbitrary theorems which require reasoning, creativity and insight and (ii) its similarity to games\u2014where AI has been spectacularly successful\u2014in that it has an automated way of determining whether a proof is successful (i.e., verified by the formal system). As demonstrated in the trivial example below, proving a formal statement requires generating a sequence of proof steps, each proof step consisting in a call to a tactic.", "images": []},
{"title": "missing", "links": "#fn1", "content": " These tactics take mathematical terms as arguments and each tactic call will transform the current statement to prove, into statements that are easier to prove, until nothing is left to prove.", "images": []},
{"title": "missing", "links": "https://cdn.openai.com/papers/Formal_Mathematics_Statement_Curriculum_Learning__ICML_2022.pdf", "content": "Since $x < 2$, $|x - 2| = -(x - 2)$. Using $p = |x - 2|$ we have $x = 2-p$ and finally $x - p = 2 - 2p$.", "images": []},
{"title": "missing", "links": "https://arxiv.org/abs/2109.00110", "content": "We observe that the capability to generate original mathematical terms required as arguments of tactics, which cannot be done without a neural language model, emerges from our training procedure. The proof below is an example of it: the proof step ", "images": []},
{"title": "missing", "links": "#fn2", "content": " (entirely generated by our models) proposes to use ", "images": []},
{"title": "missing", "links": "https://leanprover-community.github.io/mathlib_docs/tactic/ring_exp.html", "content": " as a solution, the rest of the formal proof relying on the ", "images": []},
{"title": "missing", "links": "https://leanprover-community.github.io/mathlib_docs/tactics.html#norm_num", "content": " tactic to verify that it is indeed valid.", "images": []},
{"title": "missing", "links": "#fn3", "content": "Expanding the expression we get:", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/amc-1012", "content": "$$((n + 2)! \u2212(n + 1)!) / n! = ((n + 2)(n+1)n! \u2212(n + 1)n!) / n!$$", "images": []},
{"title": "missing", "links": "https://www.maa.org/math-competitions/invitational-competitions", "content": "Dividing by $n!$ we obtain:", "images": []},
{"title": "missing", "links": "https://www.imo-official.org/", "content": "$$(n+2)(n+1) - (n+1)$$", "images": []},
{"title": "missing", "links": "#fn4", "content": "Factoring $(n+1)$ we get: $(n+1)(n+2-1) = (n+1)^2$ which concludes the proof.", "images": []},
{"title": "missing", "links": "https://imo-grand-challenge.github.io/", "content": "We also observe that our models and search procedure are capable of producing proofs that chain multiple non-trivial reasoning steps. In the proof below, the model starts by using contraposition leading to the existential statement (", "images": []},
{"title": "missing", "links": "#fnref1", "content": "). It then generates a witness for it with ", "images": []},
{"title": "missing", "links": "#fnref2", "content": " and finishes the proof by leveraging the ", "images": []},
{"title": "missing", "links": "#fnref3", "content": " tactic.", "images": []},
{"title": "missing", "links": "#fnref4", "content": "\nLet $f(x) = Ax + B$ and $g(x) = Bx + A$, where $A \\ne B$. If $f(g(x)) - g(f(x)) = B - A$, prove that $A + B = 0$.", "images": []},
{"title": "missing", "links": "/blog/authors/stanislas/", "content": "First we find that:", "images": []},
{"title": "missing", "links": "/blog/authors/jesse/", "content": "$$f(g(x)) = A(Bx + A) + B = ABx + A^2 + B$$$$g(f(x)) = B(Ax + B) + A = ABx + B^2 + A$$", "images": []},
{"title": "missing", "links": "/blog/authors/ilya/", "content": "Now we plug this back in $f(g(x)) - g(f(x)) = B - A$ and get:", "images": []},
{"title": "missing", "links": "/blog/tags/research/", "content": "$$(ABx + A^2 + B) - (ABx + B^2 + A) = B - A$$", "images": []},
{"title": "missing", "links": "/", "content": "That is:", "images": []},
{"title": "missing", "links": "/blog/openai-codex/", "content": "$$A^2 - B^2 + B - A = B - A$$", "images": []},
{"title": "missing", "links": "/fund/", "content": "Hence:", "images": []},
{"title": "missing", "links": "/blog/multimodal-neurons/", "content": "$$A^2 - B^2 = (A-B)(A+B) = 0$$", "images": []},
{"title": "missing", "links": "/blog/dall-e/", "content": "Since we are given that $A \\ne B$, necessarily, $A + B = 0$.", "images": []},
{"title": "missing", "links": "/blog/clip/", "content": "Our models, trained with ", "images": []},
{"title": "missing", "links": "/api/", "content": ", were able to close a variety of problems from training textbooks as well as ", "images": []},
{"title": "missing", "links": "/api/pricing/", "content": " and ", "images": []},
{"title": "missing", "links": "/api/examples/", "content": " competitions, and 2 problems adapted from the ", "images": []},
{"title": "missing", "links": "/api/docs/", "content": ". We present below three examples of such generated proofs.", "images": []},
{"title": "missing", "links": "/api/policies/", "content": "Rearrange to get $a(a-b)(a-c) + b(b-a)(b-c) + c(c-a)(c-b) >= 0$ which is true by Schur's inequality.", "images": []},
{"title": "missing", "links": "https://status.openai.com/", "content": "For $n \\geq 1$ we have $a(2n-1) = a(2n)-1$. Substituting this into the equation given, we get:", "images": []},
{"title": "missing", "links": "/api/login/", "content": "$$(a(2)-1) + a(2) + (a(4)-1) + a(4) + \u2026 + (a(98)-1) + (a(98)) = 137$$", "images": []},
{"title": "missing", "links": "/blog/", "content": "But the left-hand side is simply $2(a2 + a4 + a6 + \u2026 + a98) - 49$, so:", "images": []},
{"title": "missing", "links": "/blog/tags/research/", "content": "$$(a2 + a4 + a6 + \u2026 + a98) = (137 + 49) / 2 = 93$$", "images": []},
{"title": "missing", "links": "/blog/tags/announcements/", "content": "\nFor $a, b, c$ reals, prove that $(a^2 + ab + b^2)(b^2 + bc + c^2)(c^2 + ca + a^2) \\geq (ab + bc + ca)^3$.", "images": []},
{"title": "missing", "links": "/blog/tags/events/", "content": "After cancelling terms appearing on both sides, we are left to prove that:", "images": []},
{"title": "missing", "links": "/blog/tags/milestones/", "content": "$$3a^2b^2c^2 + \\sum_{sym} a^3b^2c \\leq \\sum_{cyc} a^4bc + \\sum_{cyc} (a^4b^2 + b^4c^2)$$", "images": []},
{"title": "missing", "links": "/about/", "content": "After multiplying both sides by $2$, we can rearrange the above inequality to:", "images": []},
{"title": "missing", "links": "/research/", "content": "$$0 \\leq \\sum_{cyc} (a^2b + a^2c - b^2c)^2$$", "images": []},
{"title": "missing", "links": "/publications/", "content": "which clearly holds, giving the claim.", "images": []},
{"title": "missing", "links": "/charter/", "content": "Formal mathematics involves two main challenges that make a naive application of reinforcement learning unlikely to succeed.", "images": []},
{"title": "missing", "links": "/timeline/", "content": "In our work, we address the infinite action space problem by sampling actions from a language model as we search for a proof. Language models have the capability to generate the tactic calls as well as the original mathematical terms often required as arguments. Our basis for addressing the lack of self-play is the observation that the key role of self-play in 2-player games is to provide an unsupervised curriculum. Our methodology proposes to replace this unsupervised curriculum with an auxiliary set of problem statements (without requiring proofs) of varying difficulty. We empirically show that, when the difficulty of these auxiliary problems is varied enough, our training procedure is able to solve a curriculum of increasingly difficult problems, eventually generalizing to the set of problems we care about.", "images": []},
{"title": "missing", "links": "/newsroom/", "content": "While these results are extremely exciting, as they demonstrate that deep learning models are capable of non-trivial mathematical reasoning when interacting with a formal system, we are still very far from best-student performance on these competitions, only occasionally, rather than consistently, closing challenging olympiad problems. We hope nonetheless that our work will motivate research in this domain, in particular towards the ", "images": []},
{"title": "missing", "links": "/careers/", "content": " and that the ", "images": []},
{"title": "missing", "links": "/", "content": " methodology we propose will help accelerate progress in automated reasoning in general.", "images": []},
{"title": "missing", "links": "/privacy/", "content": "Thanks to our paper co-authors: Igor Babuschkin, Kunhao Zheng and Mantas Baksys.", "images": []},
{"title": "missing", "links": "/terms/", "content": "Thanks to the students of the Xena Project Discord who helped us formalize proofs and statements (in particular: Antoine Labelle, Hanting Zhang, Shing Tak Lam, Paul Lezeau, Sara Diaz, Nikita Golikov, Yael Dillies, Artem Vasilyev, Ollie Perree, and Yourong Zang).", "images": []},
{"title": "missing", "links": "https://twitter.com/openai", "content": "Thanks in particular to Kevin Buzzard and Daniel Selsam for their support and thoughtful feedback since the very beginning of this project.", "images": []},
{"title": "missing", "links": "https://youtube.com/openai", "content": "These problems are not standard math exercises, they are used to let the best high-school students from the US (AMC12, AIME) or the world (IMO) compete against each other. ", "images": []},
{"title": "missing", "links": "https://github.com/openai/", "content": "The artifacts accepted by the formal system are low-level (like assembly code) and hard for humans to produce. Tactics are search procedures that generate such artifacts from higher level directives to assist formalization. ", "images": []},
{"title": "missing", "links": "https://soundcloud.com/openai_audio", "content": "Addendum: It was reported to us that this formal statement has an error (it should be ", "images": []},
{"title": "missing", "links": "https://linkedin.com/company/openai", "content": " instead of ", "images": []},
{"title": "missing", "links": "https://facebook.com/openai.research/", "content": " in ", "images": []},
{"title": "missing", "links": "https://twitter.com/openai", "content": "). While this error unfortunately makes the statement significantly easier than its informal version, it's an interesting example of the challenges associated with formalizing problem statements: although Lean can verify with 100% confidence that a formal proof is a correct proof of a formal statement, there is no way to automatically verify that a formal statement is \"faithful\" to an informal one. The proof of the simplified statement remains interesting so we decided to keep it in the blog post and be explicit about it with this footnote. ", "images": []},
{"title": "missing", "links": "https://youtube.com/openai", "content": "This proof is not reported in the paper as it was found by a more recent model we are still experimenting with. We decided to share it nonetheles because it's one of our favourite. ", "images": []},
{"title": "missing", "links": "https://github.com/openai/", "content": "missing", "images": []},
{"title": "missing", "links": "https://soundcloud.com/openai_audio", "content": "missing", "images": []},
{"title": "missing", "links": "https://linkedin.com/company/openai", "content": "missing", "images": []},
{"title": "missing", "links": "https://facebook.com/openai.research/", "content": "missing", "images": []}
]